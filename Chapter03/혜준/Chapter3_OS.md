# 3.1. 운영체제와 컴퓨터

## 3.1.1. 운영체제의 역할과 구조

### 운영체제(OS, Operating System)

- 사용자가 컴퓨터를 쉽게 다루게 해주는 인터페이스
- 한정된 메모리나 시스템 자원을 효율적으로 분배

        참조) 펌웨어(firmware): 운영체제와 유사하지만 소프트웨어를 추가로 설치할 수 없는 것

### 운영체제의 역할

#### 1. CPU 스케줄링과 프로세스 관리
  - CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환 관리

#### 2. 메모리 관리
  - 한정된 메모리를 어떤 프로세스에 얼마큼 할당해야 하는지 관리

#### 3. 디스크 파일 관리
  - 디스크 파일을 어떠한 방법으로 보관할지 관리

#### 4. I/O 디바이스 관리
  - I/O 디바이스들인 마우스, 키보드와 컴퓨터 간에 데이터를 주고받는 것을 관리


### 운영체제의 구조
|유저 프로그램|
|:---:|
|GUI or CUI|
|시스템콜|
|커널|
|드라이버|
|하드웨어|
        운영체제: GUI, 시스템콜, 커널, 드라이버

#### 시스템콜
- 운영체제가 커널에 접근하기 위한 인터페이스
- 유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출할 때 사용
- 유저 모드 ↔ 시스템콜 ↔ 커널 모드
- 컴퓨터 자원에 대한 직접 접근 차단하고 프로그램을 다른 프로그램으로부터 보호

![image](https://user-images.githubusercontent.com/70474860/218290114-43161f4d-c39a-49d6-9271-1c48a9af6c7e.png)


        커널: 운영체제의 핵심 부분이자 시스템콜 인터페이스를 제공하며 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 
        유저 모드: 유저가 접근할 수 있는 영역을 제한적으로 두며 컴퓨터 자원에 함부로 침범하지 못하는 모드
        커널 모드: 모든 컴퓨터 자원에 접근할 수 있는 모드


        modebit
        - 시스템 콜이 작동될 때 유저 모드와 커널 모드를 구분하는 1 또는 0의 값을 갖는 플래그 변수
        - 0: 커널 모드, 1: 유저모드
        - I/O 디바이스는 커널모드를 거쳐 운영체제를 통해 작동하게 해야 함. 유저 모드를 거치는 것보다 공격의 위험이 낮음.

## 3.1.2. 컴퓨터의 요소
- CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져 있다.
![image](https://user-images.githubusercontent.com/70474860/218253991-2b4b8765-2eeb-43a2-84a9-6e66fe611f52.png)
### CPU(Central Processing Unit)
- 산술논리연산장치, 제어장치, 레지스터로 구성되어 있는 컴퓨터 장치
- 인터럽트에 의해 단순히 메모리에 존재하는 명령어를 해석해서 실행

- **제어장치**
  - 입출력장치 간 통신을 제어하고 명령어들을 읽고 해석하며 데이터처리를 위한 순서를 결정

- **레지스터**
  - CPU 내부에 있는 매우 빠른 속도의 임시기억장치
  - CPU와 직접 연결되어 있으므로 연산 속도가 메모리에 비해 매우 빠름
  - CPU는 자체적으로 데이터를 저장할 수 없기 때문에 레지스터를 거쳐 데이터를 전달

- **산술논리연산장치**
  - 덧셈, 뺄셈 같ㅇ느 두 숫자의 산술 연산과 배타적 논리합, 논리곱 같은 논리 연산을 계산하는 디지털 회로


- **CPU의 연산 처리**

1. 제어장치➡메모리/레지스터: 계산할 값을 로드
2. 제어장치➡산술논리연산장치: 레지스터에 있는 값을 계산
3. 제어장치➡메모리/레지스터: 다시 레지스터에서 메모리로 계산한 값을 저장

- **인터럽트**
어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것
- 인터럽트 발생 요소
  - 키보드, 마우스 등 IO 디바이스로 인한 인터럽트
  - 0으로 숫자를 나누는 산술 연산에서의 인터럽트
  - 프로세스 오류
- 인터럽트 발생 ➡ 인터럽트 핸들러 함수가 있는 인터럽트 벡터에서 인터럽트 핸들러 함수 실행
- 인터럽트 간에는 우선순위에 따라 실행
- 하드웨어 인터럽트, 소프트웨어 인터럽트로 나뉨.

>✔**하드웨어 인터럽트 vs. 소프트웨어 인터럽트**<br>
>
> **하드웨어 인터럽트**: IO 디바이스에서  발생하는 인터럽트 <br>
> **소프트웨어 인터럽트**: 트랩(trap)이라고도 함. 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발동 <br>
>>✔**트랩의 종류**: <br>
>> **1.예외(Exception)**: 메모리 참조 오류, 0으로 나누기, Overflow, Underflow 등의 경우에서 발생하는 인터럽트 <br>
>> **2.시스템콜(System call)**: 사용자가 의도적으로 일으킨 인터럽트


### DMA 컨트롤러(Direct Memory Access Controller)
- I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치
- CPU 부하를 막아주며 하나의 작업을 CPU와 DMA 컨트롤러가 동시에 하는 것을 방지

### 메모리(memory)
- 전자회로에서 데이터나 상태, 명령어 등을 기록하는 장치
- RAM(Random Access Memory)을 일컬어 메모리라고도 함
- CPU = 계산 담당 = 일꾼 / 메모리 = 기억 담당 = 작업장
- 메모리가 클수록 많은 일을 동시에 할 수 있음

### 타이머(timer)
- 몇 초 안에는 작업이 끝나야 한다는 것을 정하고 특정 프로그램에 시간 제한을 다는 역할

### 디바이스 컨트롤러(device controller)
- 컴퓨터와 연결되어 있는 IO 디바이스들의 작은 CPU

# 3.2. 메모리

## 3.2.1. 메모리 계층

![image](https://user-images.githubusercontent.com/70474860/218256548-bf0d92b3-6e75-4d5d-b692-149c28aec09a.png)

### 구성
- 레지스터: CPU 안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적음.
- 캐시: L1, L2 캐시를 지칭. 휘발성, 속도 빠름, 기억 용량 적음.
- 주기억장치: RAM을 가리킴. 휘발성, 속도 보통, 기억 용량 보통.
- 보조기억장치: HDD, SSD. 비휘발성, 속도 낮음, 기억 용량 많음.

        참고) 로딩중: 하드디스크 또는 인터넷에서 데이터를 읽어 RAM으로 전송하는 과정

### 캐시(cache)
- 데이터를 미리 복사해놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상(Deadlock)을 줄이기 위한 메모리
- 캐싱 계층: 속도 차이가 너무 큰 문제를 해결하기 위해 계층과 계층 사이에 있는 계층
  - ex) 메모리와 CPU 사이에 레지스터 계층을 둬서 속도 차이 해결, 캐시 메모리와 보조기억장치 사이에 있는 주기억장치를 보조기억장치의 캐싱 계층이라 함

#### 지역성의 원리
-캐싱을 직접 설정할 때 사용하는 데이터에 대한 근거
  - 시간 지역성: 최근 사용한 데이터에 다시 접근하려는 특성
  - 공간 지역성: 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

#### 캐시히트와 캐시미스
- 캐시히트: 캐시에서 원하는 데이터를 찾는 것
- 캐시미스: 원하는 데이터가 캐시에 없다면 주 메모리로 가서 데이터를 찾아오는 것
- 캐시매핑: 캐시가 히트되기 위해 매핑하는 방법
  - 직접매핑: 순서에 따라 메모리 매핑. 처리가 빠르지만 충돌 발생이 잦음
  - 연관 매핑: 순서를 일치시키지 않고 관련 있는 캐시와 메모리 매핑. 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느림.
  - 집합 연관 매핑: 직접 매핑과 연관 매핑을 합쳐 놓은 것. 순서는 일치시키지만 집합을 두어 저장하며 블록화되어 있기 때문에 검색은 좀 더 효율적

#### 웹브라우저의 캐시
- 쿠키
  - 만료기한이 있는 키-값 저장소
  - 다른 도메인에서 요청했을 때 자동으로 전송
  - 서버에서 만료기한을 정함

- 로컬 스토리지
  - 만료기한이 없는 키-값 저장소
  - 웹 브라우저를 닫아도 유지되고 도메인 단위로 저장, 생성
  - HTML5를 지원하지 않는 웹 브라우저에서는 사용 불가
  - 클라이언트에서만 수정 가능

- 세션 스토리지
  - 만료기한이 없는 키-값 저장소
  - 탭 단위로 세션 스토리지를 생성하며, 탭을 닫을 때 데이터가 삭제
  - HTML5를 지원하지 않는 웹 브라우저에서는 사용 불가
  - 클라이언트에서만 수정 가능

#### 데이터베이스의 캐싱 계층
- 메인 데이터베이스 위의 레디스(REDIS) 데이터베이스 계층을 캐싱 계층으로 두어 성능을 향상시킴

        ❓ 레디스(redis)란?
        key와 value를 가진 NoSQL 데이터베이스

## 3.2.2. 메모리 관리

### 가상 메모리(virtual memory)
- 메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 **메모리 자원을 추상화**하여 사용자에게 매우 큰 메모리로 보이게 만드는 것
- 가상 주소(logical address): 가상적으로 주어진 주소
- 실제 주소(physical address): 실제 메모리상에 있는 주소
- 메모리관리장치(MMU): 가상주소를 실제 주소로 변환
- 페이지테이블: 가상주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어 있는 테이블
> **✔TLB**: 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시. CPU가 페이지 테이블까지 매번 가지 않도록 해 속도를 향상시키는 캐시 계층

#### 페이지 폴트와 스와핑 과정
1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 운영체제에 알림
2. 운영체제는 CPU의 동작을 잠시 멈춤
3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어 있는 프레임이 있는지 찾음. 물리 메모리에도 없는 경우 스와핑 발동
4. 비어 있는 프레임에 해당 페이지를 로드하고, 페이지 테이블을 최신화
5. 중단되었던 CPU를 다시 시작

> ✔**페이지 폴트(page fault)**: 가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 발생하는 것 <br>
> ✔**스와핑(swapping)**: 페이지 폴트가 발생했을 때, 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것

### 스레싱
- 메모리의 페이지 폴트율이 높은 것을 의미 ➡ 컴퓨터의 심각한 성능 저하 초래
- 메모리에 너무 많은 프로세스가 동시에 올라가는 경우 ➡ 스와핑 많이 발생 ➡ CPU 이용률 낮아짐 ➡ 운영체제는 CPU가 한가하다고 생각해 더 많은 프로세스를 메모리에 올림 ➡ 스레싱
- 해결방법:
  - 메모리를 늘림
  - HDD를 사용한다면 HDD를 SSD로 바꿈
  - **작업세트(working set)**
    - 프로세스의 과거 사용 이력인 지역성(locallity)을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것
    - 미리 메모리에 로드하면 탐색에 드는 비용과 스와핑을 줄일 수 있음
  - **PFF(Page Fault Frequency)**
    - 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법
    - 상한선에 도달하면 프레임을 늘리고, 하한선에 도달하면 프레임을 줄임

### 메모리 할당
- 시작 메모리 위치, 메모리의 할당 크기 기반으로 메모리 할당
- **연속 할당**: 메모리에 연속적으로 공간을 할당
  - **고정 분할 방식(fixed partition allocation)**
    - 메모리를 미리 나누어 관리하는 방식
    - 융통성이 없고, 내부 단편화가 발생
> ✔내부 단편화(internal fragmentation): 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상

  - **가변 분할 방식(variable partition allocation)**
    - 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나누어 사용
    - 내부 단편화는 발생하지 않으나 외부 단편화 발생

> ✔외부 단편화(external fragmentation): 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상

|이름|설명|
|---|---|
|최초적합|위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당|
|최적적합|프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당|
|최악적합|프로세스의 크기와 가장 많이 차이가 나는 홀에 할당|

- **불연속 할당**: 메모리를 연속적으로 할당하지 않음 ➡ 현대 운영체제가 쓰는 방법
  - **페이징(paging)**
    - 메모리를 동일한 크기의 페이지로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당
    - 홀의 크기가 균일하지 않은 문제가 없어짐
    - 주소 변환이 복잡해짐
  - **세그멘테이션(segmentation)**
    - 페이지 단위가 아닌 의미 단위인 세그먼트(segment)로 나누는 방식
    - 코드, 데이터, 함수 단위 등로 나눌 수 있음
    - 공유와 보안 측면에서 좋음
    - 홀 크기가 균일하지 않은 문제 발생
  - **페이지드 세그멘테이션(paged segmentation)**
    - 공유나 보안을 의미 단위의 세그먼트로 나누고, 물리적 메모리는 페이지로 나누는 것

### 페이지 교체 알고리즘
- **오프라인 알고리즘(offline algorithm)**: 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘. 미래에 사용되는 프로세스를 알 수 없기에 사용할 수 없지만 다른 알고리즘과의 성능 비교에 대한 기준 제공
- **FIFO(First In First Out)**: 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
- **LRU(Least Recentle Used)**
  - 참조가 가장 오래된 페이지를 교체하는 방법
  - 오래된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야 함
  - 해시테이블과 이중 연결 리스트로 구현
- **NUR(Not Used Recently)**
  - LRU에서 발전한 알고리즘으로, 일명 clock 알고리즘이라고 함
  - 0과 1을 가진 비트를 둔다.
  - 1: 최근에 참조됨
  - 0: 최근에 참조되지 않음
  - 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고, 해당 부분을 1로 바꾸는 알고리즘
- **LFU(Least Frequently Used)**: 가장 참조 횟수가 적은 페이지를 교체

# 3.3. 프로세스와 스레드

## 3.3.1. 프로세스와 컴파일 과정

### 프로세스(process)

  - 컴퓨터에서 실행되고 있는 프로그램
  - CPU 스케줄링의 대상이 되는 작업(task)이라는 용어와 거의 같은 의미로 쓰임
  - 프로그램으로부터 인스턴스화된 것

        ex) 구글 크롬 프로그램을 두 번 클릭하면 구글 크롬 '프로세스'가 시작

### 컴파일 과정
1. **전처리**: 소스코드의 주석을 제거하고 #include 등 헤더 파일을 병합하여 매크로를 치환
2. **컴파일러**: 오류 처리, 코드 최적화 작업을 하며 어셈블리어로 변환
3. **어셈블러**: 어셈블리어는 목적 코드로 변환
4. **링커**: 프로그램 내에 있는 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합하여 실행 파일을 만듦
        실행 파일의 확장자는 .exe 또는 .out이라는 확장자를 갖는다.


#### 정적 라이브러리와 동적 라이브러리
- 정적 라이브러리: 프로그램 빌드 시 라이브러리가 제공하는 모든 코드를 실행파일에 넣는 방식
  - 시스템 환경 등 외부 의존도가 낮음
  - 코드 중복 등 메모리 효율성이 떨어짐
- 동적 라이브러리: 프로그램 실행 시 필요할 때만 DLL이라는 함수 정보를 통해 참조하는 방식
  - 메모리 효율성에서의 장점
  - 외부 의존도가 높음

## 3.3.2. 프로세스의 상태
>프로세스의 상태는 생성, 대기, 대기 중단, 실행, 중단, 일시 중단, 종료 등의 상태 값을 가진다.

![image](https://user-images.githubusercontent.com/70474860/218260730-9cdbc937-95a2-4747-8ff4-117998a28173.png)


### 생성 상태(create)
- `fork()`
  - 부모 프로세스의 주소 공간을 그대로 복사하며, 새로운 자식 프로세스를 생성하는 함수
- `exec()`
  - 새롭게 프로세스를 생성하는 함수

### 대기 상태(ready)
- 메모리 공간이 ㅊ우분하면 메모리를 할당받고, 아니면 대기
- CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태

### 대기 중단 상태(ready suspended)
메모리 부족으로 일시 중단된 상태

### 실행 상태(running)
- CPU 소유권과 메모리를 할당받고 인스트럭션을 수행 중인 상태
- =CPU burst
- 
### 중단 상태(blocked)
- 어떤 이벤트가 발생한 이후 기다리며 프로세스가 차단된 상태
- I/O 디바이스에 의한 인터럽트로 발생하기도 함

### 일시 중단 상태(blocked suspended)
- 대기 중단과 유사
- 중단된 상태에서 프로세스가 실행되려고 했지만 메모리 부족으로 일시 중단된 상태

### 종료 상태(terminated)
- 메모리와 CPU 소유권을 모두 놓고 가는 상태
- 비자발적 종료(abort)
  - 자식 프로세스에 할당된 자원의 한계치를 넘어 부모 프로세스가 종료됨
  - 사용자가 `process.kill` 등 여러 명령어로 프로세스를 종료할 때 

## 3.3.3. 프로세스의 메모리 구조

![image](https://user-images.githubusercontent.com/70474860/218260808-98857a98-93d1-4777-b969-2e167d6e8758.png)

### 스택

컴파일 시에 크기가 결정되며 동적인 특징을 가짐
- 지역변수, 매개변수, 함수가 저장
- 함수가 함수를 재귀적으로 호출하면서 동적으로 크기가 늘어날 수 있음
- 힙과 스택의 메모리 영역이 겹치면 안되기 때문에 **힙과 스택 사이의 공간은 비어 있음**

### 힙
동적 할당할 때 사용하며 런타임 시 크기가 결정, 동적인 특징을 가짐

### 데이터 영역
전역변수, 정적변수가 저장되고, 정적인 특징을 갖는 프로그램이 종료되면 사라지는 변수가 들어있는 영역
- **BSS 영역**: 초기화가 되지 않은 변수가 0으로 초기화되어 저장
- **Data 영역**: 0이 아닌 다른 값으로 할당된 변수들이 저장

### 코드 영역
프로그램에 내장되어 있는 소스 코드가 들어가는 영역. 수정 불가능한 기계어로 저장되어 있으며 정적인 특징을 가짐

## 3.3.4. PCB(Process Control Block)

**PCB(Process Control Block)**: 운영체제에서 프로세스에 대한 메타데이터를 저장한 데이터
-프로세스 제어 블록
프로세스가 생성되면 운영체제는 해당 PCB 생성

>✔메타데이터: 데이터에 관한 구조화된 데이터이자 데이터를 설명하는 작은 데이터, 대량의 정보 가운데에서 찾고 있는 정보를 효율적으로 찾아내서 이용하기 위해 일정한 규칙에 따라 컨텐츠에 부여되는 데이터

### PCB의 구조
- **프로세스 스케줄링 상태**: 준비, 일시중단 등 프로세스가 CPU에 대한 소유권을 얻은 이후의 상태
- **프로세스 ID**: 프로세스 ID, 해당 프로세스의 자식 프로세스 ID
- **프로세스 권한**: 컴퓨터 자원 또는 I/O 디바이스에 대한 권한 정보
- **프로그램 카운터**: 프로세스에서 실행해야 할 다음 명령어의 주소에 대한 포인터
- **CPU 레지스터**: 프로세스를 실행하기 위해 저장해야 할 레지스터에 대한 정보
- **CPU 스케줄링 정보**: CPU 스케줄러에 의해 중단된 시간 등에 대한 정보
- **계정 정보**: 프로세스 실행에 사용된 CPU 사용량, 실행한 유저의 정보
- **I/O 상태 정보**: 프로세스에 할당된 I/O 디바이스 목록

### 컨텍스트 스위칭(context switching)
- PCB를 교환하는 과정
- 한 프로세스에 할당된 시간이 끝나거나 인터럽트에 의해 발생
- 컴퓨터는 많은 프로그램을 동시에 실행하는 것처럼 보이지만 어떠한 시점에서 실행되고 있는 프로세스는 단 한 개
- 현대 컴퓨터는 멀티코어의 CPU를 가지기 때문에 한 시점에 한 개의 프로그램이라는 설명은 틀리지만 컨텍스트 스위칭을 설명할 때는 싱글코어를 기준으로 설명

  - 한 개의 프로세스 A가 실행하다 멈춤
  - 프로세스 A의 PCB를 저장하고 프로세스 B를 로드하여 실행
  - 프로세스 B의 PCB를 저장하고 프로세스 A의 PCB를 로드
  - 컨텍스트 스위칭이 일어날 때 유휴 시간(idle time) 및 캐시미스 발생

#### 비용:캐시미스

컨텍스트 스위칭이 발생할 때 캐시클리어 과정이 일어남 ➡ 캐시 미스 발생
-스레드 컨텍스트 스위칭: 스레드는 스택 영역을 제외한 모든 메모리를 공유하기 때문에 비용이 더 적고 시간도 더 적게 걸림

## 3.3.5. 멀티프로세싱

멀티 프로세싱은 여러 개의 프로세스, 즉 멀티 프로세스를 통해 동시에 두 가지 이상의 일을 수행할 수 있는 것

### 웹 브라우저
웹 브라우저는 멀티프로세스 구조
- **브라우저 프로세스**: 주소 표시줄, 북마크 막대, 뒤로 가기 버튼, 앞으로 가기 버튼 등을 담당하며 네트워크 요청이나 파일 접근 같은 권한을 담당
- **렌더러 프로세스**: 웹 사이트가 보이는 부분의 모든 것을 제어
- **플러그인 프로세스**: 웹 사이트에서 사용하는 플러그인을 제어
- **GPU 프로세스**: GPU를 이용해서 화면을 그리는 부분을 제어

### IPC(Inter Process Communication)
- 멀티프로세스는 IPC가 가능
- **IPC**: 프로세스끼리 데이터를 주고 받고 공유 데이터를 관리하는 메커니즘
- **종류**: 공유 메모리, 파일, 소켓, 익명 파이프, 명명 파이프, 메시지 큐
- 메모리가 완전히 공유되는 스레드보다는 속도가 떨어짐

#### 공유 메모리(shared memory)
여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어 프로세스가 서로 통신할 수 있도록 공유 버퍼를 생성하는 것
- 기본적으로는 각 프로세스으 ㅣ메모리를 다른 프로세스가 접근할 수 없으나, 공유 메모리를 통해 여러 프로세스가 하나의 메모리를 공유할 수 있음
- 메모리 자체를 공유하기 때문에 불필요한 데이터 복사의 오버헤드가 발생하지 않아 가장 빠름
- 같은 메모리 영역을 여러 프로세스가 공유하기 때문에 동기화 필요

        하드웨어 관점: 공유 메모리는 CPU가 접근할 수 있는 큰 랜덤 접근 메모리인 RAM을 가리킴

#### 파일
디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터. 이를 기반으로 프로세스 간 통신함

#### 소켓
동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터를 의미하며 TCP와 UDP가 있음

#### 익명 파이프(unamed pipe)
- 프로세스 간에 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 주고받음
- 단방향 방식의 읽기 전용, 쓰기 전용 파이프를 만들어서 작동하는 방식

#### 명명된 파이프(named pipe)
- 파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향 또는 이중 파이프를 말함
- 클라이언트/서버 통신을 위한 별도의 파이프 제공
- 여러 파이프를 동시에 사용 가능
- 컴퓨터의 프로세스끼리 또는 다른 네트워크상의 컴퓨터와도 통신 가능
- 보통 서버용 파이프와 클라이언트용 파이프로 구분해서 작동하며 하나의 인스턴스를 열거나 여러 개의 인스턴스를 기반으로 통신

#### 메시지 큐
- 메시지를 큐(queue) 데이터 구조 형태로 관리하는 것
- 다른 IPC 방식에 비해서 사용 방법이 매우 직관적이고 간단
- 다른 코드의 수정 없이 몇 줄의 코드를 추가시켜 간단하게 메시지 큐에 접근할 수 있음


## 3.3.6. 스레드와 멀티스레딩

### 스레드(thread)
- 프로세스의 실행 가능한 가장 작은 단위
- 프로세스는 여러 스레드를 가질 수 있음
- 코드, 데이터, 스택, 힙을 각각 생성하는 프로세스와는 달리 스레드는 코드, 데이터, 힙은 스레드끼리 공유. 그 외의 영역은 각각 생성

### 멀티스레딩
- 프로세스 내 작업을 여러 개의 스레드, 멀티스레드로 처리하는 기법
- 스레드끼리 서로 자원을 공유하기 때문에 효율성 높음
- 동시성에도 큰 장점
- 한 스레드에 문제가 생기면 다른 스레드에도 영향을 끼쳐 스레드로 이루어져 있는 프로세스에 영향을 줄 수 있는 단점


## 3.3.7. 공유 자원과 임계 영역

### 공유 자원(shared resource)
- 시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 있는 모니터, 프린터, 메모리, 파일, 데이터 등의 자원이나 변수 등을 의미
- **경쟁 상태(race condition)**: 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황
- 동시에 접근을 시도할 때 접근의 타이밍이나 순서 등이 결과값에 영향을 줄 수 있음

### 임계 영역(critical section)
- 둘 이상의 프로세스, 스레드가 공유 자원에 접근할 때 순서 등의 이유로 결과가 달라지는 코드 영역
- 해결 방법: 뮤텍스, 세마포어, 모니터
  - 상호 배제, 한정 대기, 융통성이란 조건 만족
  - 토대가 되는 메커니즘: **잠금(lock)**

> ✔ **상호 배제**: 한 프로세스가 임계 영역에 들어갔을 때 다른 프로세스는 들어갈 수 없다. <br>
> ✔ **한정 대기**: 특정 프로세스가 영원히 임계 영역에 들어가지 못하면 안 된다. <br>
> ✔ **융통성**: 한 프로세스가 다른 프로세스의 일을 방해해서는 안된다.

#### 뮤텍스(mutex)
- 프로세스나 스레드가 공유 자원을 `lock()`을 통해 잠금 설정하고 상요한 후에는 `unlock()`을 통해 잠금 해제하는 객체
- 잠금 또는 잠금 해제라는 상태만을 가짐

#### 세마포어(semaphore)
- 일반화된 뮤텍스
- 간단한 정수 값과 두 가지 함수 `wait`(P 함수) 및 `signal`(V 함수)로 공유 자원에 대한 접근 처리
- `wait()`: 자신의 차례가 올 때까지 기다리는 함수
- `signal()`: 다음 프로세스로 순서를 넘겨주는 함수
- **바이너리 세마포어**: 0과 1의 두 가지 값만 가질 수 있는 세마포어
- **카운팅 세마포어**: 여러 개의 값을 가질 수 있는 세마포어. 여러 자원에 대한 접근을 제어하는 데 사용

#### 모니터
- 둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유 자원을 숨기고 해당 접근에 대해 인터페이스만 적용
- 모니터는 세마포어보다 구현하기 쉬움. 모니터에서 상호 배제는 자동이지만 세마포어에서는 명시적으로 구현해야 함

## 3.3.8. 교착 상태(deadlock)
두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태

### 교착 상태의 원인
1. **상호 배제**: 한 프로세스가 자원을 독점하고 있으며 다른 프로세스들은 접근이 불가능
2. **점유 대기**: 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태
3. **비선점**: 다른 프로세스의 자원을 강제적으로 가져올 수 없음
4. **환형 대기**: 프로세스 A는 프로세스 B의 자원을 요구하고, 프로세스 B는 프로세스 A의 자원을 요구하는 등 서로가 서로의 자원을 요구하는 상황

### 교착 상태 해결 방법
1. 자원을 할당할 때 애초에 조건이 성립되지 않도록 설계
2. 교착 상태 가능성이 없을 때만 자원 할당되며, 프로세스당 요청할 자원들의 최대치를 통해 자원 할당 가능 여부를 파악하는 '은행원 알고리즘'을 씀
3. 교착 상태가 발생하면 사이클이 있는지 찾아보고 이에 관련된 프로세스를 한 개씩 지움
4. 교착 상태(deadlock)은 매우 드물게 일어나기 대문에 이를 처리하는 비용이 더 커서 교착 상태가 발생하면 사용자가 작업을 종료. 현대 운영체제는 이 방법을 채택.

> ✔ **은행원 알고리즘**: 총 자원의 양과 현재 할당한 자원의 양을 기준으로 안정 또는 불안정 상태로 나누고 안정 상태로 가도록 자원을 할당하는 알고리즘

# 3.4. CPU 스케줄링 알고리즘
- CPU 스케줄링 알고리즘에 따라 프로세스에서 해야 하는 일을 스레드 단위로 CPU에 할당
- 프로그램이 실행될 때는 CPU 스케줄링 알고리즘이 어떤 프로글매에 CPU 소유권 줄지 결정
- 알고리즘은 CPU 이용률은 높게, 주어진 시간에 많은 일을 하게, 준비 큐에 있는 프로세스는 적게, 응답시간을 짧게 설정하는 것을 목표로 함

## 3.4.1. 비선점형 방식(non-preemptive)
- 프로세스가 스스로 CPU 소유권을 포기하는 방식
- 강제로 프로세스를 중지하지 않음
- 컨텍스트 스위칭으로 인한 부하가 적음

### FCFS(First Come, First Served)
가장 먼저 온 것을 가장 먼저 처리하는 알고리즘
❗ 준비 큐에서 오래 기다리는 현상(convoy effect) 발생 가능

### SJF(Shortest Job First)
실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘
❗ 긴 시간을 가진 프로세스가 실행되지 않는 현상(starvation)이 일어나며 평균 대기 시간이 가장 짧음

### 우선순위
SJF 스케줄링에서 오래된 작업일수록 우선순위를 높이는 방법(aging)을 통해 단점을 보완한 알고리즘

## 3.4.2. 선점형 방식(preemptive)
- 현대 운영체제가 쓰는 방식
- 지금 사용하고 있는 프로세스를 알고리즘에 의해 중단시켜 버리고 강제로 다른 프로세스에 CPU 소유권을 할당하는 방식

### 라운드 로빈(RR, Round Robin)
- 현대 컴퓨터가 쓰는 스케줄링인 우선순위 스케줄링(priority scheduling)의 일종
- 각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐(ready queue)의 뒤로 가는 알고리즘

### SRF
- 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지하고 해당 프로세스를 수행하는 알고리즘

### 다단계 큐
- 우선 순위에 따른 준비 큐를 여러 개 사용
- 큐마다 라운드 로빈이나 FCFS 등 다른 스케줄링 알고리즘을 적용
- 큐 간의 프로세스 이동이 안되므로 스케줄링 부담이 적지만 유연성이 떨어지는 특징
